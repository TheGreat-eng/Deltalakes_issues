This PR addresses issue #41 - Support for AWS S3 (multiple clusters/drivers/JVMs)

It implements few ideas from #41 discussion:
  - provides generic base class BaseExternalLogStore for storing listing of commit files
    in external DB. This class may be easly extended for specific DB backend
  - stores contents of commit in temporary file and links to it in DB's row
    to be able to finish uncompleted write operation while reading
  - provides concrete DynamoDBLogStore implementation extending BaseExternalLogStore
  - implementations for other DB backends should be simple to implement
    (ZooKeeper implementation is almost ready, I can create separate PR if anyone is interested)

## DynamoDBLogStore requirements:

To enable DynamoDBLogStore set following spark property:
`
spark.delta.logStore.class=io.delta.storage.DynamoDBLogStore
`

Single dynamodb table is required. Default table name is 'delta_log',
it may be changed by setting spark property.

Required key schema:
  - parentPath: String, HASH
  - filename: String, RANGE

Table may be created with following aws cli command:

```
aws --region us-east-1 dynamodb create-table \
    --table-name delta_log \
    --attribute-definitions AttributeName=tablePath,AttributeType=S \
                            AttributeName=fileName,AttributeType=S \
    --key-schema AttributeName=tablePath,KeyType=HASH \
                AttributeName=fileName,KeyType=RANGE \
    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5
```


Following spark properties are recognized:
- spark.delta.DynamoDBLogStore.tableName - table name (defaults to 'delta_log')
- spark.delta.DynamoDBLogStore.region - AWS region (defaults to 'us-east-1')

## Testing

Python integration test is included :examples/python/dynamodb_logstore.py

This solution has been also stress-tested on Amazon's EMR cluster 
(mutiple test jobs writing thousands of parallel transactions to single delta table)
and no data loss has beed observed so far

