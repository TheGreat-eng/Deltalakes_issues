Hi, i have got this error while i was trying to write data from spark structured streaming to delta using Scala 2.12 and delta-core 0.5.0 .
Below, you can see the code of the call and the dataframe schema.
I'm not an expert in Scala so probably could be an Scala error, the mehod showed is in a scala class without any object.

Any idea what is happening?.

Thanks in advance.

```scala
2020-02-28 19:44:56 - onApplicationEvent error: 
java.util.concurrent.ExecutionException: org.apache.spark.SparkException: Task not serializable
	at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:299)
	at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:286)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)
	at com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(Uninterruptibles.java:135)
	at com.google.common.cache.LocalCache$Segment.getAndRecordStats(LocalCache.java:2346)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2318)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2280)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2195)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3934)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4736)
	at org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:740)
	at org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:712)
	at org.apache.spark.sql.delta.sources.DeltaSink.<init>(DeltaSink.scala:41)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createSink(DeltaDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.DataSource.createSink(DataSource.scala:284)
	at org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:322)
	at com.ingest.spark.streamingTest.StreamTest.onApplicationEvent(StreamTest.scala:73)
	at com.ingest.spark.streamingTest.StreamTest.onApplicationEvent(StreamTest.scala:31)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139)
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:403)
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:360)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:897)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:553)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at com.ingest.spark.streamingTest.Main$.main(Application2.scala:19)
	at com.ingest.spark.streamingTest.Main.main(Application2.scala)
Caused by: org.apache.spark.SparkException: Task not serializable
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:403)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:393)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2326)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$1(RDD.scala:850)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:849)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:630)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:89)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.MapPartitionsExec.doExecute(objects.scala:185)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)
	at org.apache.spark.sql.execution.SerializeFromObjectExec.inputRDDs(objects.scala:110)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
	at org.apache.spark.sql.delta.util.StateCache$CachedDS.<init>(StateCache.scala:48)
	at org.apache.spark.sql.delta.util.StateCache.cacheDS(StateCache.scala:104)
	at org.apache.spark.sql.delta.util.StateCache.cacheDS$(StateCache.scala:103)
	at org.apache.spark.sql.delta.Snapshot.cacheDS(Snapshot.scala:54)
	at org.apache.spark.sql.delta.Snapshot.<init>(Snapshot.scala:118)
	at org.apache.spark.sql.delta.DeltaLog.$anonfun$currentSnapshot$12(DeltaLog.scala:177)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:177)
	at org.apache.spark.sql.delta.DeltaLog$$anon$3.$anonfun$call$2(DeltaLog.scala:744)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)
	at org.apache.spark.sql.delta.DeltaLog$$anon$3.$anonfun$call$1(DeltaLog.scala:744)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:77)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:67)
	at org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:671)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:103)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:89)
	at org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:671)
	at org.apache.spark.sql.delta.DeltaLog$$anon$3.call(DeltaLog.scala:743)
	at org.apache.spark.sql.delta.DeltaLog$$anon$3.call(DeltaLog.scala:740)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4739)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3524)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2317)
	... 24 common frames omitted
Caused by: java.io.NotSerializableException: scala.runtime.LazyRef
Serialization stack:
	- object not serializable (class: scala.runtime.LazyRef, value: LazyRef thunk)
	- element of array (index: 2)
	- array (class [Ljava.lang.Object;, size 3)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;)
	- object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.apache.spark.sql.catalyst.expressions.ScalaUDF, functionalInterfaceMethod=scala/Function1.apply:(Ljava/lang/Object;)Ljava/lang/Object;, implementation=invokeStatic org/apache/spark/sql/catalyst/expressions/ScalaUDF.$anonfun$f$2:(Lscala/Function1;Lorg/apache/spark/sql/catalyst/expressions/Expression;Lscala/runtime/LazyRef;Lorg/apache/spark/sql/catalyst/InternalRow;)Ljava/lang/Object;, instantiatedMethodType=(Lorg/apache/spark/sql/catalyst/InternalRow;)Ljava/lang/Object;, numCaptured=3])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class org.apache.spark.sql.catalyst.expressions.ScalaUDF$$Lambda$1422/922304163, org.apache.spark.sql.catalyst.expressions.ScalaUDF$$Lambda$1422/922304163@68e4b277)
	- field (class: org.apache.spark.sql.catalyst.expressions.ScalaUDF, name: f, type: interface scala.Function1)
	- object (class org.apache.spark.sql.catalyst.expressions.ScalaUDF, UDF(input_file_name()))
	- field (class: org.apache.spark.sql.catalyst.expressions.Alias, name: child, type: class org.apache.spark.sql.catalyst.expressions.Expression)
	- object (class org.apache.spark.sql.catalyst.expressions.Alias, UDF(input_file_name()) AS file#66)
	- writeObject data (class: scala.collection.immutable.List$SerializationProxy)
	- object (class scala.collection.immutable.List$SerializationProxy, scala.collection.immutable.List$SerializationProxy@18f52e63)
	- writeReplace data (class: scala.collection.immutable.List$SerializationProxy)
	- object (class scala.collection.immutable.$colon$colon, List(txn#60, add#61, remove#62, metaData#63, protocol#64, commitInfo#65, UDF(input_file_name()) AS file#66))
	- field (class: org.apache.spark.sql.execution.ProjectExec, name: projectList, type: interface scala.collection.Seq)
	- object (class org.apache.spark.sql.execution.ProjectExec, Project [txn#60, add#61, remove#62, metaData#63, protocol#64, commitInfo#65, UDF(input_file_name()) AS file#66]
+- SerializeFromObject [if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn)) null else named_struct(appId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).appId, true, false), version, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).version, lastUpdated, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).lastUpdated)) AS txn#60, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).path, true, false), partitionValues, externalmaptocatalyst(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).partitionValues), size, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).size, modificationTime, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).modificationTime, dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).dataChange, stats, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).stats, true, false), tags, externalmaptocatalyst(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).tags)) AS add#61, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).path, true, false), deletionTimestamp, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).deletionTimestamp), dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).dataChange) AS remove#62, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData)) null else named_struct(id, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).id, true, false), name, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).name, true, false), description, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).description, true, false), format, if (isnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format)) null else named_struct(provider, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).provider, true, false), options, externalmaptocatalyst(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).options)), schemaString, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).schemaString, true, false), partitionColumns, mapobjects(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).partitionColumns, None), configuration, externalmaptocatalyst(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).configuration), createdTime, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).createdTime)) AS metaData#63, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol)) null else named_struct(minReaderVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minReaderVersion, minWriterVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minWriterVersion) AS protocol#64, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo)) null else named_struct(version, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).version), timestamp, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).timestamp, true, false), userId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userId), true, false), userName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userName), true, false), operation, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operation, true, false), operationParameters, externalmaptocatalyst(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operationParameters), job, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job))) null else named_struct(jobId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobId, true, false), jobName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobName, true, false), runId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).runId, true, false), jobOwnerId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobOwnerId, true, false), triggerType, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).triggerType, true, false)), notebook, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook))) null else named_struct(notebookId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook)).notebookId, true, false)), clusterId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).clusterId), true, false), readVersion, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).readVersion), isolationLevel, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isolationLevel), true, false), isBlindAppend, unwrapoption(BooleanType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isBlindAppend)) AS commitInfo#65]
   +- MapPartitions org.apache.spark.sql.delta.Snapshot$$Lambda$1406/644912106@5df3f854, obj#59: org.apache.spark.sql.delta.actions.SingleAction
      +- DeserializeToObject newInstance(class org.apache.spark.sql.delta.actions.SingleAction), obj#58: org.apache.spark.sql.delta.actions.SingleAction
         +- Union
            :- Scan ExistingRDD[txn#18,add#19,remove#20,metaData#21,protocol#22,commitInfo#23]
            +- Scan ExistingRDD[txn#43,add#44,remove#45,metaData#46,protocol#47,commitInfo#48]
)
	- field (class: org.apache.spark.sql.execution.WholeStageCodegenExec, name: child, type: class org.apache.spark.sql.execution.SparkPlan)
	- object (class org.apache.spark.sql.execution.WholeStageCodegenExec, *(1) Project [txn#60, add#61, remove#62, metaData#63, protocol#64, commitInfo#65, UDF(input_file_name()) AS file#66]
+- *(1) SerializeFromObject [if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn)) null else named_struct(appId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).appId, true, false), version, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).version, lastUpdated, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).lastUpdated)) AS txn#60, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).path, true, false), partitionValues, externalmaptocatalyst(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).partitionValues), size, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).size, modificationTime, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).modificationTime, dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).dataChange, stats, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).stats, true, false), tags, externalmaptocatalyst(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).tags)) AS add#61, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).path, true, false), deletionTimestamp, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).deletionTimestamp), dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).dataChange) AS remove#62, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData)) null else named_struct(id, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).id, true, false), name, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).name, true, false), description, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).description, true, false), format, if (isnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format)) null else named_struct(provider, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).provider, true, false), options, externalmaptocatalyst(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).options)), schemaString, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).schemaString, true, false), partitionColumns, mapobjects(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).partitionColumns, None), configuration, externalmaptocatalyst(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).configuration), createdTime, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).createdTime)) AS metaData#63, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol)) null else named_struct(minReaderVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minReaderVersion, minWriterVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minWriterVersion) AS protocol#64, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo)) null else named_struct(version, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).version), timestamp, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).timestamp, true, false), userId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userId), true, false), userName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userName), true, false), operation, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operation, true, false), operationParameters, externalmaptocatalyst(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operationParameters), job, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job))) null else named_struct(jobId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobId, true, false), jobName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobName, true, false), runId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).runId, true, false), jobOwnerId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobOwnerId, true, false), triggerType, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).triggerType, true, false)), notebook, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook))) null else named_struct(notebookId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook)).notebookId, true, false)), clusterId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).clusterId), true, false), readVersion, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).readVersion), isolationLevel, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isolationLevel), true, false), isBlindAppend, unwrapoption(BooleanType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isBlindAppend)) AS commitInfo#65]
   +- MapPartitions org.apache.spark.sql.delta.Snapshot$$Lambda$1406/644912106@5df3f854, obj#59: org.apache.spark.sql.delta.actions.SingleAction
      +- DeserializeToObject newInstance(class org.apache.spark.sql.delta.actions.SingleAction), obj#58: org.apache.spark.sql.delta.actions.SingleAction
         +- Union
            :- Scan ExistingRDD[txn#18,add#19,remove#20,metaData#21,protocol#22,commitInfo#23]
            +- Scan ExistingRDD[txn#43,add#44,remove#45,metaData#46,protocol#47,commitInfo#48]
)
	- field (class: org.apache.spark.sql.execution.exchange.ShuffleExchangeExec, name: child, type: class org.apache.spark.sql.execution.SparkPlan)
	- object (class org.apache.spark.sql.execution.exchange.ShuffleExchangeExec, Exchange hashpartitioning(coalesce(add#61.path, remove#62.path), 50)
+- *(1) Project [txn#60, add#61, remove#62, metaData#63, protocol#64, commitInfo#65, UDF(input_file_name()) AS file#66]
   +- *(1) SerializeFromObject [if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn)) null else named_struct(appId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).appId, true, false), version, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).version, lastUpdated, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).lastUpdated)) AS txn#60, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).path, true, false), partitionValues, externalmaptocatalyst(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).partitionValues), size, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).size, modificationTime, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).modificationTime, dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).dataChange, stats, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).stats, true, false), tags, externalmaptocatalyst(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).tags)) AS add#61, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).path, true, false), deletionTimestamp, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).deletionTimestamp), dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).dataChange) AS remove#62, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData)) null else named_struct(id, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).id, true, false), name, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).name, true, false), description, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).description, true, false), format, if (isnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format)) null else named_struct(provider, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).provider, true, false), options, externalmaptocatalyst(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).options)), schemaString, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).schemaString, true, false), partitionColumns, mapobjects(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).partitionColumns, None), configuration, externalmaptocatalyst(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).configuration), createdTime, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).createdTime)) AS metaData#63, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol)) null else named_struct(minReaderVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minReaderVersion, minWriterVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minWriterVersion) AS protocol#64, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo)) null else named_struct(version, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).version), timestamp, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).timestamp, true, false), userId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userId), true, false), userName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userName), true, false), operation, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operation, true, false), operationParameters, externalmaptocatalyst(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operationParameters), job, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job))) null else named_struct(jobId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobId, true, false), jobName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobName, true, false), runId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).runId, true, false), jobOwnerId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobOwnerId, true, false), triggerType, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).triggerType, true, false)), notebook, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook))) null else named_struct(notebookId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook)).notebookId, true, false)), clusterId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).clusterId), true, false), readVersion, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).readVersion), isolationLevel, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isolationLevel), true, false), isBlindAppend, unwrapoption(BooleanType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isBlindAppend)) AS commitInfo#65]
      +- MapPartitions org.apache.spark.sql.delta.Snapshot$$Lambda$1406/644912106@5df3f854, obj#59: org.apache.spark.sql.delta.actions.SingleAction
         +- DeserializeToObject newInstance(class org.apache.spark.sql.delta.actions.SingleAction), obj#58: org.apache.spark.sql.delta.actions.SingleAction
            +- Union
               :- Scan ExistingRDD[txn#18,add#19,remove#20,metaData#21,protocol#22,commitInfo#23]
               +- Scan ExistingRDD[txn#43,add#44,remove#45,metaData#46,protocol#47,commitInfo#48]
)
	- field (class: org.apache.spark.sql.execution.InputAdapter, name: child, type: class org.apache.spark.sql.execution.SparkPlan)
	- object (class org.apache.spark.sql.execution.InputAdapter, Exchange hashpartitioning(coalesce(add#61.path, remove#62.path), 50)
+- *(1) Project [txn#60, add#61, remove#62, metaData#63, protocol#64, commitInfo#65, UDF(input_file_name()) AS file#66]
   +- *(1) SerializeFromObject [if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn)) null else named_struct(appId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).appId, true, false), version, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).version, lastUpdated, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).lastUpdated)) AS txn#60, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).path, true, false), partitionValues, externalmaptocatalyst(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).partitionValues), size, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).size, modificationTime, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).modificationTime, dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).dataChange, stats, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).stats, true, false), tags, externalmaptocatalyst(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).tags)) AS add#61, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).path, true, false), deletionTimestamp, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).deletionTimestamp), dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).dataChange) AS remove#62, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData)) null else named_struct(id, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).id, true, false), name, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).name, true, false), description, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).description, true, false), format, if (isnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format)) null else named_struct(provider, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).provider, true, false), options, externalmaptocatalyst(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).options)), schemaString, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).schemaString, true, false), partitionColumns, mapobjects(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).partitionColumns, None), configuration, externalmaptocatalyst(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).configuration), createdTime, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).createdTime)) AS metaData#63, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol)) null else named_struct(minReaderVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minReaderVersion, minWriterVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minWriterVersion) AS protocol#64, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo)) null else named_struct(version, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).version), timestamp, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).timestamp, true, false), userId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userId), true, false), userName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userName), true, false), operation, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operation, true, false), operationParameters, externalmaptocatalyst(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operationParameters), job, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job))) null else named_struct(jobId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobId, true, false), jobName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobName, true, false), runId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).runId, true, false), jobOwnerId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobOwnerId, true, false), triggerType, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).triggerType, true, false)), notebook, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook))) null else named_struct(notebookId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook)).notebookId, true, false)), clusterId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).clusterId), true, false), readVersion, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).readVersion), isolationLevel, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isolationLevel), true, false), isBlindAppend, unwrapoption(BooleanType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isBlindAppend)) AS commitInfo#65]
      +- MapPartitions org.apache.spark.sql.delta.Snapshot$$Lambda$1406/644912106@5df3f854, obj#59: org.apache.spark.sql.delta.actions.SingleAction
         +- DeserializeToObject newInstance(class org.apache.spark.sql.delta.actions.SingleAction), obj#58: org.apache.spark.sql.delta.actions.SingleAction
            +- Union
               :- Scan ExistingRDD[txn#18,add#19,remove#20,metaData#21,protocol#22,commitInfo#23]
               +- Scan ExistingRDD[txn#43,add#44,remove#45,metaData#46,protocol#47,commitInfo#48]
)
	- field (class: org.apache.spark.sql.execution.SortExec, name: child, type: class org.apache.spark.sql.execution.SparkPlan)
	- object (class org.apache.spark.sql.execution.SortExec, Sort [file#66 ASC NULLS FIRST], false, 0
+- Exchange hashpartitioning(coalesce(add#61.path, remove#62.path), 50)
   +- *(1) Project [txn#60, add#61, remove#62, metaData#63, protocol#64, commitInfo#65, UDF(input_file_name()) AS file#66]
      +- *(1) SerializeFromObject [if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn)) null else named_struct(appId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).appId, true, false), version, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).version, lastUpdated, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).txn).lastUpdated)) AS txn#60, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).path, true, false), partitionValues, externalmaptocatalyst(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key5, ExternalMapToCatalyst_key_isNull5, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value5, ExternalMapToCatalyst_value_isNull5, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).partitionValues), size, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).size, modificationTime, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).modificationTime, dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).dataChange, stats, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).stats, true, false), tags, externalmaptocatalyst(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key6, ExternalMapToCatalyst_key_isNull6, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value6, ExternalMapToCatalyst_value_isNull6, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).add).tags)) AS add#61, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove)) null else named_struct(path, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).path, true, false), deletionTimestamp, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).deletionTimestamp), dataChange, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).remove).dataChange) AS remove#62, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData)) null else named_struct(id, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).id, true, false), name, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).name, true, false), description, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).description, true, false), format, if (isnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format)) null else named_struct(provider, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).provider, true, false), options, externalmaptocatalyst(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key7, ExternalMapToCatalyst_key_isNull7, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value7, ExternalMapToCatalyst_value_isNull7, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).format).options)), schemaString, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).schemaString, true, false), partitionColumns, mapobjects(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(MapObjects_loopValue45, MapObjects_loopIsNull45, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).partitionColumns, None), configuration, externalmaptocatalyst(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key8, ExternalMapToCatalyst_key_isNull8, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value8, ExternalMapToCatalyst_value_isNull8, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).configuration), createdTime, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).metaData).createdTime)) AS metaData#63, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol)) null else named_struct(minReaderVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minReaderVersion, minWriterVersion, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).protocol).minWriterVersion) AS protocol#64, if (isnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo)) null else named_struct(version, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).version), timestamp, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).timestamp, true, false), userId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userId), true, false), userName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).userName), true, false), operation, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operation, true, false), operationParameters, externalmaptocatalyst(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_key9, ExternalMapToCatalyst_key_isNull9, ObjectType(class java.lang.String), true), true, false), ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, lambdavariable(ExternalMapToCatalyst_value9, ExternalMapToCatalyst_value_isNull9, ObjectType(class java.lang.String), true), true, false), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).operationParameters), job, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job))) null else named_struct(jobId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobId, true, false), jobName, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobName, true, false), runId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).runId, true, false), jobOwnerId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).jobOwnerId, true, false), triggerType, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.JobInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).job)).triggerType, true, false)), notebook, if (isnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook))) null else named_struct(notebookId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(unwrapoption(ObjectType(class org.apache.spark.sql.delta.actions.NotebookInfo), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).notebook)).notebookId, true, false)), clusterId, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).clusterId), true, false), readVersion, unwrapoption(LongType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).readVersion), isolationLevel, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, unwrapoption(ObjectType(class java.lang.String), assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isolationLevel), true, false), isBlindAppend, unwrapoption(BooleanType, assertnotnull(assertnotnull(input[0, org.apache.spark.sql.delta.actions.SingleAction, true]).commitInfo).isBlindAppend)) AS commitInfo#65]
         +- MapPartitions org.apache.spark.sql.delta.Snapshot$$Lambda$1406/644912106@5df3f854, obj#59: org.apache.spark.sql.delta.actions.SingleAction
            +- DeserializeToObject newInstance(class org.apache.spark.sql.delta.actions.SingleAction), obj#58: org.apache.spark.sql.delta.actions.SingleAction
               +- Union
                  :- Scan ExistingRDD[txn#18,add#19,remove#20,metaData#21,protocol#22,commitInfo#23]
                  +- Scan ExistingRDD[txn#43,add#44,remove#45,metaData#46,protocol#47,commitInfo#48]
)
	- element of array (index: 0)
	- array (class [Ljava.lang.Object;, size 4)
	- element of array (index: 1)
	- array (class [Ljava.lang.Object;, size 3)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;)
	- object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.apache.spark.sql.execution.WholeStageCodegenExec, functionalInterfaceMethod=scala/Function2.apply:(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;, implementation=invokeStatic org/apache/spark/sql/execution/WholeStageCodegenExec.$anonfun$doExecute$4$adapted:(Lorg/apache/spark/sql/catalyst/expressions/codegen/CodeAndComment;[Ljava/lang/Object;Lorg/apache/spark/sql/execution/metric/SQLMetric;Ljava/lang/Object;Lscala/collection/Iterator;)Lscala/collection/Iterator;, instantiatedMethodType=(Ljava/lang/Object;Lscala/collection/Iterator;)Lscala/collection/Iterator;, numCaptured=3])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class org.apache.spark.sql.execution.WholeStageCodegenExec$$Lambda$1694/629286877, org.apache.spark.sql.execution.WholeStageCodegenExec$$Lambda$1694/629286877@4518e64)
	at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:400)
	... 82 common frames omitted
```


```scala
def writeToDelta(messagesAggregate:Dataset[Row]):Unit = {
        try{
    		var queryDelta:StreamingQuery = messagesAggregate
    		    .writeStream
                    // NOT OK
    		    //.format("delta") 
        	    //.format("org.apache.spark.sql.delta.sources.DeltaDataSource")
                    //OK
        	    .format("parquet") 
                    .outputMode("append")
        	    .option("checkpointLocation", "/tmp/checkpoint2")
        	    .option("path", hiveWarehouse)
        	    .trigger(Trigger.ProcessingTime(100000))
        	    .start();

    		queryDelta.awaitTermination()
		
		}catch {
            case e:Exception => log.error("onApplicationEvent error: ",e)
        }
        
    }
```
The dataframe contains data of this form:

> root
>  |-- store_id: integer (nullable = true)
>  |-- ticket_id: integer (nullable = true)
>  |-- employee_id: integer (nullable = true)
>  |-- total_cost: double (nullable = true)
>  |-- num_items: integer (nullable = true)
>  |-- sale_date: long (nullable = true)
>  |-- cod: integer (nullable = false)
>  |-- name: string (nullable = false)
>  |-- discount: integer (nullable = false)
>  |-- init: long (nullable = true)
>  |-- end: long (nullable = true)

Code to reproce the error:
https://github.com/anigmo97/SimpleExamples/tree/master/Spark_streaming_deltalake_scala