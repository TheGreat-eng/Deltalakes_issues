## Bug

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the issue title
For example: [BUG][Spark] Title of my issue
-->

- [x] Spark
- [ ] Standalone
- [ ] Flink
- [ ] Kernel
- [ ] Other (fill in here)

### Describe the problem

#### Steps to reproduce

Please include copy-pastable code snippets if possible.
1. `create table default.test (c1 int, c2 int) using delta partitioned by (c2) TBLPROPERTIES('delta.columnMapping.mode'='name');`
2. `alter table default.test drop column c1;`

#### Observed results

Creating tables with all partition columns (e.g. `create table default.test2 (a int) using delta partitioned by (c2)`) throws "Cannot use all columns for partition columns" error message, but dropping last non-partition columns succeeds.

#### Expected results

Throw exceptions when the target column of `DROP COLUMN` is the last non-partition column. 

#### Further details

<!--
Include any additional details that may be useful for diagnosing the problem here. If including tracebacks, please include the full traceback. Large logs and files should be attached.
-->

### Environment information

* Delta Lake version: 2.3.0
* Spark version: 3.3.2
* Scala version: 2.12

### Willingness to contribute

The Delta Lake Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the Delta Lake code base?

- [x] No. I cannot contribute a bug fix at this time.
