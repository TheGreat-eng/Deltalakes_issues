<!--
Thanks for sending a pull request!  Here are some tips for you:
  1. If this is your first time, please read our contributor guidelines: https://github.com/delta-io/delta/blob/master/CONTRIBUTING.md
  2. If the PR is unfinished, add '[WIP]' in your PR title, e.g., '[WIP] Your PR title ...'.
  3. Be sure to keep the PR description updated to reflect all changes.
  4. Please write your PR title to summarize what this PR proposes.
  5. If possible, provide a concise example to reproduce the issue for a faster review.
  6. If applicable, include the corresponding issue number in the PR title and link it in the body.
-->

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the pull request title
For example: [Spark] Title of my pull request
-->

- [x] Spark
- [ ] Standalone
- [ ] Flink
- [ ] Kernel
- [ ] Other (fill in here)

## What changes were proposed in this pull request?

### Context
Schema evolution in the MERGE INTO command relies on manually updating the plan of the target table and replaces the original output attributes to match the schema after evolution.
Manually updating the target plan is unnecessarily complex, error-prone and ultimately wrong: the new attributes don't match the actual target schema that was used to resolve all expressions. This worked so far for schema evolution that only adds new fields or columns that are then implicitly filled with `null`s on read but breaks when introducing type evolution due to type mismatches that can't be reconciled.

### Changes
The target plan isn't manually updated to support schema evolution in the MERGE INTO command anymore. Instead, the original target output is used and we rely on the different expressions used to write out the data to produce an output that supports schema evolution. E.p.:
- For target columns that are assigned to by an UPDATE action: `generateUpdateExpressions` already does the heavy lifting, it is simply updated to use the actual target output instead of trying to reference the evolved schema. This allows simplifying a bit the method.
- For target columns that aren't assigned to by an UPDATE action (either columns without an assignment or with a DELETE action and the deleted row must be written to the CDC output): no-op expressions are generated by casting the target output attributes to their corresponding type after evolution in `getTargetOutputCols`.

The manual handling in `buildTargetPlanWithIndex` and `replaceFileIndex` that isn't needed anymore is removed. This in turn allow splitting `replaceFileIndex` in two methods with separate concerns: `replaceFileIndex` (already exists) and `dropColumns` to manually remove columns from the target plan.

## How was this patch tested?
This is extensively covered by existing MERGE tests, in particular:
- `MergeIntoSchemaEvolutionTests`
- `MergeCDCSuite` - `schema evolution with non-nullable schema` that covers handling non nullable fields that turn nullable due to the outer join in MERGE.
