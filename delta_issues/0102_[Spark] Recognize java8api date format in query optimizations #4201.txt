<!--
Thanks for sending a pull request!  Here are some tips for you:
  1. If this is your first time, please read our contributor guidelines: https://github.com/delta-io/delta/blob/master/CONTRIBUTING.md
  2. If the PR is unfinished, add '[WIP]' in your PR title, e.g., '[WIP] Your PR title ...'.
  3. Be sure to keep the PR description updated to reflect all changes.
  4. Please write your PR title to summarize what this PR proposes.
  5. If possible, provide a concise example to reproduce the issue for a faster review.
  6. If applicable, include the corresponding issue number in the PR title and link it in the body.
-->

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the pull request title
For example: [Spark] Title of my pull request
-->

- [x] Spark
- [ ] Standalone
- [ ] Flink
- [ ] Kernel
- [ ] Other (fill in here)

## Description
 
Resolves #4201
The _convertValueIfRequired_ function casts DateType columns to java.sql.Date. Optimizing subqueries involving date columns with spark.sql.datetime.java8API.enabled set to true currently results in ClassCastException errors. This fix correctly converts dates regardless of the java type of the date value.

## How was this patch tested?

A unit test was added to verify that the optimizations now work regardless of the value of the spark.sql.datetime.java8API.enabled  configuration (without this fix the unit test is failing).

## Does this PR introduce _any_ user-facing changes?
No
