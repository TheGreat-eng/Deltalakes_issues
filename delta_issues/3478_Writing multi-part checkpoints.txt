The protocol defines a possibility to write multi-part checkpoints. In the current version of open-source Delta Lake (1.0.0), Spark always writes a single checkpoint file. It can become a bottleneck, especially in a streaming application. I suggest to implement such multi-part checkpoints writing with a configurable parameter to control the number of parts (eg. based on a size of the previous checkpoint or a number of files in the table).