## Bug

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the issue title
For example: [BUG][Spark] Title of my issue
-->

- [x] Spark
- [ ] Standalone
- [ ] Flink
- [ ] Kernel
- [ ] Other (fill in here)

### Describe the problem

It seems Data skipping can perform poorly if the filter on z-ordered column is using `.isIn(<filter list>)` filter condition. As done [here](https://github.com/delta-io/delta/blob/master/spark/src/main/scala/org/apache/spark/sql/delta/stats/DataSkippingReader.scala#L549). So for example, if my filter list only contains 2 values and there's a gap between these two values. Then the files overlapped with `[my filter list val1, my filter list val2]` will be scanned and it's more performant if convert this filter condition to `val =  my filter list val1 or val = my filter list val2`

#### Steps to reproduce

<!--
Please include copy-pastable code snippets if possible.
1. _____
2. _____
3. _____
-->

#### Observed results

<!-- What happened?  This could be a description, log output, etc. -->

#### Expected results

<!-- What did you expect to happen? -->

#### Further details

<!--
Include any additional details that may be useful for diagnosing the problem here. If including tracebacks, please include the full traceback. Large logs and files should be attached.
-->

### Environment information

* Delta Lake version:
* Spark version:
* Scala version:

### Willingness to contribute

The Delta Lake Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the Delta Lake code base?

- [ ] Yes. I can contribute a fix for this bug independently.
- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the Delta Lake community.
- [ ] No. I cannot contribute a bug fix at this time.
