Much like this issue here https://issues.apache.org/jira/browse/SPARK-23514, during `LogStore` instantiation [here](https://github.com/delta-io/delta/blob/master/core/src/main/scala/org/apache/spark/sql/delta/storage/LogStore.scala#L277) if we instead use `spark.sessionState.newHadoopConf` then we will automatically get the settings from the SQLConf available in the hadoop conf.