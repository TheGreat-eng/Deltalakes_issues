## Bug

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the issue title
For example: [BUG][Spark] Title of my issue
-->

- [ ] Spark
- [ ] Standalone
- [ ] Flink
- [X] Kernel
- [ ] Other (fill in here)

### Describe the problem

#### Steps to reproduce

<!--
Please include copy-pastable code snippets if possible.
1. _____
2. _____
3. _____
-->

I observe the following error 
Failed to parse JSON string: {"numRecords":1,"minValues":{"id1":"id1"},"maxValues":{"id1":"id1"},"nullCount":{"id1":0}} 

at first glance, the depending library may not working with it

https://github.com/delta-io/delta/blob/685379c8bda4c98b1cd9e5d1c73eb2fe155a6d1e/kernel/kernel-api/src/main/java/io/delta/kernel/internal/util/JsonUtils.java#L30-L42

I'll need a further look

#### Observed results

<!-- What happened?  This could be a description, log output, etc. -->

#### Expected results

<!-- What did you expect to happen? -->

#### Further details

<!--
Include any additional details that may be useful for diagnosing the problem here. If including tracebacks, please include the full traceback. Large logs and files should be attached.
-->

### Environment information

* Delta Lake version:
* Spark version:
* Scala version:

### Willingness to contribute

The Delta Lake Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the Delta Lake code base?

- [x] Yes. I can contribute a fix for this bug independently.
- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the Delta Lake community.
- [ ] No. I cannot contribute a bug fix at this time.
