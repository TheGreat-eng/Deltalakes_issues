## Bug

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the issue title
For example: [BUG][Spark] Title of my issue
-->

- [ ] Spark
- [ ] Standalone
- [x] Flink
- [ ] Kernel
- [ ] Other (fill in here)

### Describe the problem

#### Steps to reproduce

<!--
Please include copy-pastable code snippets if possible.
1. _____
2. _____
3. _____
-->

1. My FlinkSQL template for reading kafka stream data and writing to s3 storage
```
CREATE TABLE source_kafka_table
(
     `event_info` string comment 'source event'
    ,`source_partition` int METADATA FROM 'partition'
    ,`source_offset` bigint METADATA FROM 'offset'
    ,`source_timestamp` timestamp(3) METADATA FROM 'timestamp'
    ,`proc_time` AS PROCTIME()
) WITH (
    'connector' = 'kafka',
    'properties.bootstrap.servers' = 'xxxxxxxxx:9092',
    'topic' = 'source_topic',
    'scan.startup.mode' = 'latest-offset',
    'value.format' = 'json'
);

CREATE CATALOG delta 
WITH (
  'type' = 'delta-catalog'
);
CREATE DATABASE IF NOT EXISTS delta.tmp; 

CREATE TABLE if not exists delta.tmp.tmp_test_flink_sink_delta_table (
     `event_info`         String    
    ,`source_partition`   string
    ,`source_offset`      string
    ,`source_timestamp`   string
    ,`dt`                 string    
    ,`hr`                 string    
)
PARTITIONED BY (dt, hr)
WITH (
  'connector' = 'delta',
  'table-path' = 's3://s3-tmp-bucket/tmp.db/tmp_test_flink_sink_delta_table/' 
);

INSERT INTO delta.tmp.tmp_test_flink_sink_delta_table
SELECT 
     `event_info`
    ,`source_partition`
    ,`source_offset`
    ,`source_timestamp`
    ,date_format(`source_timestamp`, 'yyyyMMdd') as dt
    ,date_format(`source_timestamp`, 'HH') as hr 
FROM 
    `source_kafka_table`
; 
```

#### Observed results

<!-- What happened?  This could be a description, log output, etc. -->
Within a minute, a new Delta log file is created, which rapidly grows to over 700 in size. The absence of a checkpoint file indicates that no compaction operation has been performed. 
![image](https://github.com/delta-io/delta/assets/18416349/0b16b29a-6194-48e3-a34a-c04979f5bfa0)


#### Expected results

<!-- What did you expect to happen? -->
How to perform log compaction in Flink.


#### Further details

<!--
Include any additional details that may be useful for diagnosing the problem here. If including tracebacks, please include the full traceback. Large logs and files should be attached.
-->

### Environment information

* Delta Lake version:3.1.0
* Flink version:1.18

### Willingness to contribute

The Delta Lake Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the Delta Lake code base?

- [ ] Yes. I can contribute a fix for this bug independently.
- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the Delta Lake community.
- [ ] No. I cannot contribute a bug fix at this time.
