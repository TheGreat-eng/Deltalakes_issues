<!--
Thanks for sending a pull request!  Here are some tips for you:
  1. If this is your first time, please read our contributor guidelines: https://github.com/delta-io/delta/blob/master/CONTRIBUTING.md
  2. If the PR is unfinished, add '[WIP]' in your PR title, e.g., '[WIP] Your PR title ...'.
  3. Be sure to keep the PR description updated to reflect all changes.
  4. Please write your PR title to summarize what this PR proposes.
  5. If possible, provide a concise example to reproduce the issue for a faster review.
  6. If applicable, include the corresponding issue number in the PR title and link it in the body.
-->

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the pull request title
For example: [Spark] Title of my pull request
-->

- [x] Spark
- [ ] Standalone
- [ ] Flink
- [ ] Kernel
- [ ] Other (fill in here)

## Description

Function `SchemaUtils.normalizeSchemaNames()` is used during a Delta write. It was intended to correct the case of names of any top level-fields that differed between the input schema and the table. If the case of any nested field differed, the function was supposed to raise an exception.

However, due to a long-standing bug, the function could instead ignore the difference in the nested fields. This results in a data corruption. While the column values are written into the Delta table, the stats for these column are not gathered correctly. Instead, the stats are recorded as-if the column was missing in the input, that is: `minValue = null`, `maxValue = null`, `nullCount = rowCount`.

This PR implements the full normalization of nested field names to fix this.

## How was this patch tested?

New tests in `SchemaUtilsSuite.scala`.

## Does this PR introduce _any_ user-facing changes?

No.
