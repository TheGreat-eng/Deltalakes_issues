## Bug [Spark] issue when merge using autoMerge property 
#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the issue title
For example: [BUG][Spark] Title of my issue
-->

- [x] Spark
- [ ] Standalone
- [ ] Flink
- [ ] Kernel
- [ ] Other (fill in here)

### Describe the problem
Merge operation with an insert/update Expr condition doesn't support using an alias when referencing the target table.
and the conf `"spark.databricks.delta.schema.autoMerge.enabled"` is enabled. Aliasing work fine when the parameter is off.

Let's suppose the target table has the alias t and the source has the alias s, when we define the Expr condition like that

Supposing new_col is an additional column for the target table, giving such a map `Map( "t.new_col"- >  "s.new_col") `raises the error. 

#### Steps to reproduce

<!--
Please include copy-pastable code snippets if possible.
1. _____
2. _____
3. _____
-->
Run the code below. Update the variable into the updateExpr/insertExpr to reproduce the issue.
`
// spark.conf.set("spark.databricks.delta.schema.autoMerge.enabled","true") <- this cannot be enabled at run time. it has to be set when the spark session is initializing.

    // val basePath = "My amazing path"
    val targetPath = s"$basePath/target_table/"
    val updatesDF = sparkSession.range(20).selectExpr("id", "(id*1000) as new_col")
    sparkSession.range(10).write.format("delta").save(targetPath)
    val target = DeltaTable.forPath(sparkSession, targetPath)

    val badColumnsMap = Map("target.new_col" -> "source.new_col")
    val goodColumnsMap = Map("new_col" -> "source.new_col")

    target
      .alias("target")
      .merge(updatesDF.alias("source"), "target.id = source.id")
      .whenMatched()
      .updateExpr(goodColumnsMap) // insert  badColumnsMap for error
      .whenNotMatched()
      .insertExpr(goodColumnsMap) // insert  badColumnsMap for error
      .execute()
    DeltaTable.forPath(sparkSession, targetPath).toDF.show()
`
#### Observed results

When `val goodColumnsMap = Map("new_col" -> "source.new_col")` is given as updateExpr/insertExpr condition, the merge runs smoothly as expected.


When `val badColumnsMap = Map("target.new_col" -> "source.new_col") ` is given as updateExpr/insertExpr condition, an error will be raised.

Merge Op
```
    target
      .alias("target")
      .merge(updatesDF.alias("source"), "target.id = source.id")
      .whenMatched()
      .updateExpr(badColumnsMap)
      .whenNotMatched()
      .insertExpr(badColumnsMap)
      .execute()
    DeltaTable.forPath(sparkSession, targetPath).toDF.show()
```
ERROR LOG
```
[DELTA_MERGE_UNRESOLVED_EXPRESSION] Cannot resolve target.new_col in UPDATE clause given columns source.id, source.new_col
org.apache.spark.sql.delta.DeltaAnalysisException: [DELTA_MERGE_UNRESOLVED_EXPRESSION] Cannot resolve target.new_col in UPDATE clause given columns source.id, source.new_col
	at org.apache.spark.sql.delta.ResolveDeltaMergeInto$.$anonfun$resolveReferencesAndSchema$4(ResolveDeltaMergeInto.scala:81)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.sql.delta.ResolveDeltaMergeInto$.assertResolved$1(ResolveDeltaMergeInto.scala:74)
	at org.apache.spark.sql.delta.ResolveDeltaMergeInto$.$anonfun$resolveReferencesAndSchema$1(ResolveDeltaMergeInto.scala:60)
	at org.apache.spark.sql.delta.ResolveDeltaMergeInto$.$anonfun$resolveReferencesAndSchema$1$adapted(ResolveDeltaMergeInto.scala:60)
	at scala.collection.immutable.List.foreach(List.scala:431)
```

<!-- What happened?  This could be a description, log output, etc. -->

#### Expected results

<!-- What did you expect to happen? -->
I do expect there is no different behavior between the 2 cases. So the merge should run smooth.

#### Further details

<!--
Include any additional details that may be useful for diagnosing the problem here. If including tracebacks, please include the full traceback. Large logs and files should be attached.
-->

### Environment information

* Delta Lake version: 3.2.0
* Spark version: 3.5.0
* Scala version: 2.13.0

### Willingness to contribute

The Delta Lake Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the Delta Lake code base?

- [ ] Yes. I can contribute a fix for this bug independently.
- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the Delta Lake community.
- [ ] No. I cannot contribute a bug fix at this time.
