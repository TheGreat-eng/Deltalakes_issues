## Bug

#### Which Delta project/connector is this regarding?
<!--
Please add the component selected below to the beginning of the issue title
For example: [BUG][Spark] Title of my issue
-->

- [ ] Spark
- [ ] Standalone
- [x] Flink
- [ ] Kernel
- [ ] Other (fill in here)

### Describe the problem
Have create a delta sink in Flink application which write to AWS s3. Job is running file when ran on local as credentials are provided part of Environment Variable. When I deployed on flink cluster on kubernetes providing Hadoop conf as below
`conf.set("fs.s3a.aws.credentials.provider", "com.amazonaws.auth.WebIdentityTokenCredentialsProvider")`


The error stack trance.

`2023-12-15T06:07:38.5545198Z stdout F Caused by: org.apache.hadoop.fs.s3a.auth.NoAuthWithAWSException: No AWS Credentials provided by DynamicTemporaryAWSCredentialsProvider TemporaryAWSCredentialsProvider SimpleAWSCredentialsProvider EnvironmentVariableCredentialsProvider IAMInstanceCredentialsProvider : com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables (AWS_ACCESS_KEY_ID (or AWS_ACCESS_KEY) and AWS_SECRET_KEY (or AWS_SECRET_ACCESS_KEY))`

I can see only below classes.
`DynamicTemporaryAWSCredentialsProvider`
`TemporaryAWSCredentialsProvider`
`SimpleAWSCredentialsProvider`
`EnvironmentVariableCredentialsProvider`
`IAMInstanceCredentialsProvider`

Notes: The source is also AWS kinesis using same I am able to process the records.
#### Steps to reproduce

<!--
Please include copy-pastable code snippets if possible.
  private def createDeltaSink(inputStream: DataStream[RowData], deltaTablePath: String, schema: RowType): Unit = {
    val partitionCols = Array("alias","date")

      val prodConf = new Configuration()
      prodConf.set("fs.s3a.aws.credentials.provider", "com.amazonaws.auth.WebIdentityTokenCredentialsProvider")
      prodConf.set("fs.s3a.fast.upload.buffer", "array")
      prodConf.set("fs.s3a.fast.upload.active.blocks", "4")

      prodConf.set("fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")
      prodConf.set("fs.s3a.endpoint", "s3.amazonaws.com")

      prodConf.setBoolean("fs.s3a.path.style.access", true)
      prodConf.setBoolean("fs.s3a.audit.enabled", false)
      prodConf.set("fs.s3a.threads.max", String.valueOf(200))
      prodConf.set("fs.s3a.connection.maximum", String.valueOf(136))
      prodConf.set("fs.s3a.bucket.probe", "0")
      prodConf.set("fs.s3a.experimental.input.fadvise", "random")
      prodConf.set("fs.s3a.ssl.channel.mode", "default_jsse_with_gcm")
      prodConf.set("fs.creation.parallel.count", "14")

    val deltaSink = DeltaSink
      .forRowData(
        new Path(deltaTablePath),
        prodConf,
        schema)
      .withPartitionColumns(partitionCols: _*)
      .build()

    inputStream.sinkTo(deltaSink)
  }
-->

#### Observed results

<!-- What happened?  This could be a description, log output, etc. -->

#### Expected results

<!-- What did you expect to happen? -->

#### Further details

<!--
Include any additional details that may be useful for diagnosing the problem here. If including tracebacks, please include the full traceback. Large logs and files should be attached.
-->

### Environment information

 scala.version=2.12.7
 scala.binary=2.12
 flink.version=1.17.0
 flink-s3-fs-hadoop=1.17.0
 delta-version=3.0.0
 hadoop-client=3.1.0

### Willingness to contribute

The Delta Lake Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the Delta Lake code base?

- [ ] Yes. I can contribute a fix for this bug independently.
- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the Delta Lake community.
- [x] No. I cannot contribute a bug fix at this time.
